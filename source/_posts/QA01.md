---
title: QA01
date: 2023-07-03 18:49:47
tags: 
  - px4
  - ubuntu
  - mavsdk
  - yolo
categories: 
  - 南工御风
top_img: https://images.weserv.nl/?url=https://hanhan3344-tx-bk-1313563340.cos.ap-guangzhou.myqcloud.com/typora/elysia05.jpg&default=https://hanhan3344-tx-bk-1313563340.cos.ap-guangzhou.myqcloud.com/typora/elysia05.jpg
cover: https://images.weserv.nl/?url=https://hanhan3344-tx-bk-1313563340.cos.ap-guangzhou.myqcloud.com/typora/24-08-B.jpg&default=https://hanhan3344-tx-bk-1313563340.cos.ap-guangzhou.myqcloud.com/typora/24-08-B.jpg
---

# QA01

## 目标任务要求不够详细，不知道是什么

> 参考QQ群文件的“中国飞行器设计创新大赛规则（2023年).pdf ->固定翼无人机侦察与打击 ->5.竞赛方法”

### 5.6 A、B 两个机组同时上场。比赛计时指令发出时，由参赛选手开启计时器，然后携带任务箱从出发线行进至操纵区，完成组装、调试和起飞。飞行器携带模拟弹飞离起降区即为起飞成功。

- 在比赛开始后需完成飞行器飞控部分的启动，按照去年的说法就是：打开电脑、启动图传、运行比赛程序、在程序中看到飞行器状态ok后告诉队友，准备起飞。  

​	![飞行器状态ok，可以起飞](https://hanhan3344-tx-bk-1313563340.cos.ap-guangzhou.myqcloud.com/typora/image-20230507185941651.png)  

> 图片来源：https://www.hanhan3344.top/ 顶栏→[2022CADC_录屏 && 图传资料](https://www.aliyundrive.com/s/YEEhfchRVAq)→录屏文件夹→Desktop 2022.11.30 - 15.01.28.02.mp4

### 5.7 参赛选手可自由选择自动或手动的方式起飞。若选择自动方式起飞，须在飞行器起飞前将遥控器置于地面；若选择手动方式起飞，须在飞行器进入目标区之前将遥控器置于地面，以确认自主飞行切换成功。

- 今年新增的加分项目，自动起飞，可以参考PX4 User Guide中的takeoff部分https://docs.px4.io/main/en/flight_modes/takeoff.html#fixed-wing-fw

### 5.8 飞行器执行侦察和打击任务时必须为自主飞行状态。侦察任务为 A 机组识别红色天井中的数字，B 机组识别蓝色天井中的数字。完成侦察后，对“中位数”所在的天井进行打击，打击结果以模拟弹第一落点为准。

- ==自主飞行状态==意味着我们在*起飞后→降落前*不能通过电脑（或遥控器）再对飞机进行任何远程操作，所以编写程序要一步到位。

- ==识别天井中的数字==：

  - 如何从图传传回来的视频流中识别天井中的数字呢？首先我们需要**目标检测算法**对图传视频画面进行实例分割，这样我们就能得到画面中的标靶部分。  

    ![image-20230507191406347](https://hanhan3344-tx-bk-1313563340.cos.ap-guangzhou.myqcloud.com/typora/image-20230507191406347.png)  

    > 图片来源：[去年比赛提交的视频](https://www.bilibili.com/video/BV1HP411T7C9/?spm_id_from=333.999.0.0&vd_source=374b2a05cf4288dee623676fbe5a8ca6)（地面端录制）那么目标检测算法从哪里来呢？~~自己写一个~~开源好用的yolov5就是

  - 那么目标检测算法从哪里来呢？~~自己写一个~~[yolov5](https://github.com/ultralytics/yolov5)就是一个开源又好用的目标检测（实例分割）算法

    > 我们新的 YOLOv5 [release v7.0](https://github.com/ultralytics/yolov5/releases/v7.0) 实例分割模型是世界上最快和最准确的模型，击败所有当前 [SOTA 基准](https://paperswithcode.com/sota/real-time-instance-segmentation-on-mscoco)。我们使它非常易于训练、验证和部署。更多细节请查看 [发行说明](https://github.com/ultralytics/yolov5/releases/v7.0) 或访问我们的 [YOLOv5 分割 Colab 笔记本](https://github.com/ultralytics/yolov5/blob/master/segment/tutorial.ipynb) 以快速入门。
    >
    > ——来自yolov5项目首页的介绍（readme.md）

  - 在将标靶部分从视频帧中分离出来后，标靶的数字又该怎么识别呢？~~自己写一个~~[paddleocr](https://github.com/PaddlePaddle/PaddleOCR)就是一个开源又好用的ocr（Optical Character Recognition，光学字符识别）工具

- 在解决了以上问题后，我们现在已经可以获得标靶中的数字，我们将得到的三个数字比较一下，算出中位数，然后我们再通过捕获帧中中位数标靶的像素位置，通过与飞机传回的GPS位置做比对，计算得出中位数标靶的GPS位置（**TODO**）。

- 在计算出中位数标靶的GPS坐标后，我们就可以让飞机自动进入投弹模式，在去年的程序中，程序将会控制飞机取消正在进行的侦察mission，并生成一个包含中位数标靶的GPS坐标的投弹mission发送给飞机执行。

### 5.9 参赛选手可自由选择自动或手动的方式着陆。若选择自动方式着陆，在飞行器着陆且完全静止后方能拿起遥控器；若选择手动方式降落，在侦察与打击任务完成后方能拿起遥控器，操纵飞行器返航着陆。

- 自动着陆，新增加分项，参考PX4 User Guide中的land部分https://docs.px4.io/main/en/flight_modes/land.html#fixed-wing-fw

## 怎么去了解学习（具体途径）

### yolov5

- [官方的简体中文文档](https://github.com/ultralytics/yolov5/blob/master/README.zh-CN.md)。其中有详细的安装、推理、训练等教程  

  ![yolov5官方教程](https://hanhan3344-tx-bk-1313563340.cos.ap-guangzhou.myqcloud.com/typora/image-20230507193632234.png)  

### paddleocr

- [官方的简体中文文档](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/README_ch.md)。里面有更详细的安装、推理、训练教程，推荐看[一行命令快速使用](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_ch/quickstart.md)部分（不是只看这部分）

### PX4 && mavsdk

- PX4是一个飞控的系统，就好像你的电脑有windows、linux、mac系统，手机有Android、IOS系统，飞控也有一个开源系统叫PX4。

- mavsdk是一个PX4的api，我们想要让飞行器实现自动飞行、自主完成任务、并且与自制的标靶识别功能完美融合，仅仅使用市面上的QGC等地面站软件是做不到的，但是不用QGC等地面站软件我们该怎么控制飞机呢？（你最好知道QGC是可以操控飞机完成一些自动飞行任务的😅）PX4的mavsdk就给我们创造了途径。那么mavsdk和px4有什么关系呢？在PX4 User Guide的[Drone kit](https://docs.px4.io/main/en/robotics/dronekit.html#dronekit)目录中就有说明。（想必大家都是熟读过PX4 User Guide的🤣）

  > 不再推荐使用 DroneKit。
  >
  > 你应该改用[MAVSDK （打开新窗口）](https://mavsdk.mavlink.io/)使用 PX4，因为它几乎在所有方面都更好：功能、速度、编程语言支持、维护等。
  >
  > ~~可以在此处找到有关将 DroneKit 与 PX4 结合使用的文档：[PX4 v1.12 > DroneKit （打开新窗口）](https://docs.px4.io/v1.12/en/robotics/dronekit.html).~~

  我们打开MAVSDK的链接，来到MAVSDK的官网，可以看到MAVSDK的介绍

  > *MAVSDK*是各种编程语言的库集合，用于与[MAVLink](https://mavlink.io/en/)系统（如无人机、相机或地面系统）接口。
  >
  > 这些库提供了一个简单的 API，用于管理一个或多个车辆，提供对车辆信息和遥测的编程访问，以及对任务、移动和其他操作的控制。
  >
  > 这些库可以在无人机上的配套计算机上使用，也可以在地面上用于地面站或移动设备。
  >
  > MAVSDK 是跨平台的：Linux、macOS、Windows、Android 和 iOS。

  意思就是我们可以用它提供的api，通过python等编程语言，在pc上直接与飞控交互，用来控制飞行器、获取飞行器信息等。那么我们该怎么使用呢？  

  ![image-20230507195142210](https://hanhan3344-tx-bk-1313563340.cos.ap-guangzhou.myqcloud.com/typora/image-20230507195142210.png)  

  点击进入python的页面中，在这里有两个选项  

  ![image-20230507195237518](https://hanhan3344-tx-bk-1313563340.cos.ap-guangzhou.myqcloud.com/typora/image-20230507195237518.png)  

  点击第一个[Python QuickStart](https://mavsdk.mavlink.io/main/en/python/quickstart.html)我们可以进入Python QuickStart，里面有从安装到在模拟器运行、arm、takeoff、land的教程。如果你觉得示例不够多，https://github.com/mavlink/MAVSDK-Python/tree/main/examples里面有更多的官方示例。

